{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "qJZ-zuXV0JmT",
        "5BC7kJb6hqiK"
      ],
      "authorship_tag": "ABX9TyNp3/7MsnMQYBmqWzHprIhS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ElanElanElanElan/DiffusingColab/blob/main/DiffusingGradio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Diffusing colab by using python! the way god intended**\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "qJZ-zuXV0JmT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gDkEJvt4e1-Y",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title **Installing** and **importing** all neccesary and semi neccesary stuff\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "import os\n",
        "import shutil\n",
        "import time\n",
        "from PIL import Image\n",
        "!pip install --upgrade gradio diffusers accelerate transformers xformers safetensors\n",
        "import gradio as gr\n",
        "import torch\n",
        "from diffusers import DiffusionPipeline,StableDiffusionPipeline,StableDiffusionXLPipeline,DPMSolverMultistepScheduler,AutoencoderTiny"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title use drive and create the setup folders\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!mkdir Loras\n",
        "!mkdir Outputs\n",
        "!mkdir Plots\n",
        "lora_folder = '/content/Loras'\n",
        "output_folder = '/content/Outputs'\n",
        "plot_folder = \"/content/Plots\""
      ],
      "metadata": {
        "id": "zaXRyA4xwbHA",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title select which useful base model and optimization to use\n",
        "Enter_model = \"Sdxl\" # @param [\"Sdxl\", \"1.5\"]\n",
        "if Enter_model == 'Sdxl':\n",
        "    model_id = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
        "    Pipeline =  StableDiffusionXLPipeline.from_pretrained(model_id, torch_dtype=torch.float16,variant=\"fp16\", safety_checker=None, use_safetensors=True)\n",
        "    Pipeline.scheduler = DPMSolverMultistepScheduler.from_config(Pipeline.scheduler.config)\n",
        "else:\n",
        "    model_id = \"runwayml/stable-diffusion-v1-5\"\n",
        "    Pipeline =  StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16,variant=\"fp16\", safety_checker=None, use_safetensors=True)\n",
        "    Pipeline.scheduler = DPMSolverMultistepScheduler.from_config(Pipeline.scheduler.config)\n",
        "\n",
        "enter_optimisation = \"optimised\" #@param [\"none\",'optimised']\n",
        "if enter_optimisation == \"optimised\":\n",
        "    Pipeline.vae = AutoencoderTiny.from_pretrained(\"madebyollin/taesdxl\", torch_dtype=torch.float16)\n",
        "    Pipeline.enable_attention_slicing()\n",
        "    Pipeline.enable_vae_slicing()\n",
        "    Pipeline.enable_vae_tiling()\n",
        "    Pipeline.to('cuda')\n"
      ],
      "metadata": {
        "id": "a0kKOEJ_Xn0z",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title run the cell below to define all the functions you will use (feel free to inspect)\n",
        "def Loading_Lora(lora_name_string):\n",
        "    lora_list = os.listdir(lora_folder)\n",
        "    matching_files = [filename for filename in lora_list if lora_name_string in filename]\n",
        "\n",
        "    if not matching_files:\n",
        "        print(f\"No matching files found for '{lora_name_string}' in {lora_folder}.\")\n",
        "        return None\n",
        "\n",
        "    if len(matching_files) == 1:\n",
        "\n",
        "        selected_file = matching_files[0]\n",
        "        Pipeline.load_lora_weights(os.path.join(lora_folder, selected_file))\n",
        "        return Pipeline\n",
        "    else:\n",
        "        print(\"more than one lora with matching names, be more specific in the naming\")\n",
        "\n",
        "def basic_generator(input_prompt: str, number_of_pics: int, steps: int, width = 1024, height = 1024, Use_Lora: bool = False, Lora_name: str = None) -> list:\n",
        "    number_of_pics = int(number_of_pics)\n",
        "    steps = int(steps)\n",
        "    width = int(width)\n",
        "    height = int(height)\n",
        "\n",
        "    if Use_Lora and Lora_name is None:\n",
        "        raise ValueError(\"If 'Use_Lora' is True, 'Lora_name' must be provided.\")\n",
        "    elif not Use_Lora and Lora_name is not None:\n",
        "        raise ValueError(\"If 'Use_Lora' is False, 'Lora_name' should not be provided.\")\n",
        "    if Use_Lora is True:\n",
        "        Loading_Lora(Lora_name)\n",
        "        output = [Pipeline(prompt = input_prompt, num_inference_steps= steps, width = width, height = height).images for i in range(number_of_pics)]\n",
        "    else:\n",
        "        output = [Pipeline(prompt = input_prompt, num_inference_steps= steps, width = width, height = height).images for i in range(number_of_pics)]\n",
        "    image_paths = []\n",
        "    for index, image in enumerate(output):\n",
        "        file_name = f\"image{index}.png\"\n",
        "        if file_name in os.listdir(output_folder):\n",
        "            file_name = f\"image{len(os.listdir(output_folder))}.png\"\n",
        "        image[0].save(os.path.join(output_folder, file_name), \"PNG\")\n",
        "        image_paths.append(os.path.join(output_folder,file_name))\n",
        "    Pipeline.unload_lora_weights()\n",
        "    return image_paths\n",
        "\n",
        "def plot_images(image_paths:list = None):\n",
        "    if image_paths is None:\n",
        "        image_paths = [\n",
        "            os.path.join(output_folder, filename)\n",
        "            for filename in os.listdir(output_folder)\n",
        "            if os.path.isfile(os.path.join(output_folder, filename))\n",
        "        ]\n",
        "\n",
        "    num_images = len(image_paths)\n",
        "    num_rows = int(num_images ** 0.5)\n",
        "    num_cols = (num_images + num_rows - 1) // num_rows\n",
        "    fig, axes = plt.subplots(num_rows, num_cols)\n",
        "    for i, ax in enumerate(axes.ravel()):\n",
        "        if i < len(image_paths):\n",
        "            img = Image.open(image_paths[i])\n",
        "            ax.imshow(img)\n",
        "            ax.axis('off')\n",
        "\n",
        "    i = len(os.listdir(plot_folder))\n",
        "    while True:\n",
        "        plt_name = os.path.join(plot_folder, f\"plot{i}.jpg\")\n",
        "        if plt_name in os.listdir(plot_folder):\n",
        "            plt_name = os.path.join(plot_folder, f\"plot{i+1}.jpg\")\n",
        "            i += 1\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    plt.savefig(plt_name, bbox_inches=\"tight\")\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "Fog9h144NlGs",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "---\n",
        "overview-\n",
        "---\n",
        "\n",
        "\n",
        "Use the *Code Cell below* to run the pipeline using the **functions, files,imports,etc** defined in the *above code cell(s)*\n",
        "\n",
        "# For reference-\n",
        "\n",
        "1.  **`basic_generator(\"anime waifu\", 2,20)`** will get you 2 individual anime waifus pics made in 20 steps each in the output folder\n",
        "2.  **`plot_images(basic_generator(\"anime waifus\",12,30))`** will you get you your 12 anime waifus made with 30 steps each on a single image in the plot directory\n",
        "3. simple_generator() also accepts a singular lora now, for example: `basic_generator(\"close up ttg style image of ttrvn by the beach in a colorful dress\", 4, 20, Use_Lora = True, Lora_name = \"Raven_XL-000004\") `make sure lora name is in the Lora directory\n",
        "4. you can provide width and height as arguements in simple generator (uses 1024 by 1024 whether sdxl or 1.5 so better change if you using 1.5)\n",
        "5. using plot_images() alone would plot all images in the output folder\n",
        "\n"
      ],
      "metadata": {
        "id": "YkO6LaUX7r03"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_images(basic_generator(\"full body anime woman on a beach, solo, anime, sunny environment, joyful expression\",6,25, height= 1152, width= 896))"
      ],
      "metadata": {
        "id": "q7sdjXSIdE6_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Utility cells below**\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "5BC7kJb6hqiK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title run the cell to copy stuff from gdrive like loras, to the appropriate folders\n",
        "user_input = \"Raven_XL\" #@param {type:\"string\"}\n",
        "google_drive_folder = \"/content/drive/\" #@param {type:\"string\"}\n",
        "directoryto = lora_folder # @param [\"lora_folder\"] {type:\"raw\"}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "full_content = os.listdir(google_drive_folder)\n",
        "\n",
        "\n",
        "for file in full_content:\n",
        "    if user_input in file:\n",
        "        source_path = os.path.join(google_drive_folder, file)\n",
        "        shutil.copy(source_path, directoryto)\n"
      ],
      "metadata": {
        "id": "M0GCgjFP1Kh3",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title run the **`Gradio`** interface (not completed)\n",
        "#Iface = gr.Interface(fn=user_inputs, inputs= [\"text\",\"number\"], outputs= \"image\")\n",
        "#Iface.launch(debug=True)"
      ],
      "metadata": {
        "id": "dg4vYAZnVaK1",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}