{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOJYveXrryimDUQbF7ylf2E",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ElanElanElanElan/DiffusingColab/blob/main/DiffusingGradio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gDkEJvt4e1-Y",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title **Installing** and **importing** all neccesary and semi neccesary stuff\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "import os\n",
        "import shutil\n",
        "import time\n",
        "from PIL import Image\n",
        "!pip install --upgrade gradio diffusers accelerate transformers xformers safetensors\n",
        "import gradio as gr\n",
        "import torch\n",
        "from diffusers import DiffusionPipeline,StableDiffusionPipeline,StableDiffusionXLPipeline,DPMSolverMultistepScheduler,AutoencoderTiny"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title use drive and create the setup folders\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!mkdir Loras\n",
        "!mkdir Outputs\n",
        "!mkdir Plots\n",
        "lora_folder = '/content/Loras'\n",
        "output_folder = '/content/Outputs'\n",
        "plot_folder = \"/content/Plots\""
      ],
      "metadata": {
        "id": "zaXRyA4xwbHA",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title select which useful base model and optimization to use\n",
        "Enter_model = \"Sdxl\" # @param [\"Sdxl\", \"1.5\"]\n",
        "if Enter_model == 'Sdxl':\n",
        "    model_id = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
        "    Pipeline =  StableDiffusionXLPipeline.from_pretrained(model_id, torch_dtype=torch.float16,variant=\"fp16\", safety_checker=None, use_safetensors=True)\n",
        "    Pipeline.scheduler = DPMSolverMultistepScheduler.from_config(Pipeline.scheduler.config)\n",
        "else:\n",
        "    model_id = \"runwayml/stable-diffusion-v1-5\"\n",
        "    Pipeline =  StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16,variant=\"fp16\", safety_checker=None, use_safetensors=True)\n",
        "    Pipeline.scheduler = DPMSolverMultistepScheduler.from_config(Pipeline.scheduler.config)\n",
        "\n",
        "enter_optimisation = \"optimised\" #@param [\"none\",'optimised']\n",
        "if enter_optimisation == \"optimised\":\n",
        "    Pipeline.vae = AutoencoderTiny.from_pretrained(\"madebyollin/taesdxl\", torch_dtype=torch.float16)\n",
        "    Pipeline.enable_attention_slicing()\n",
        "    Pipeline.enable_vae_slicing()\n",
        "    Pipeline.enable_vae_tiling()\n",
        "    Pipeline.to('cuda')\n"
      ],
      "metadata": {
        "id": "a0kKOEJ_Xn0z",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "run all the def function cells below"
      ],
      "metadata": {
        "id": "vcRdDyDngF2_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def basic_generator(input_prompt: str, number_of_pics: int):\n",
        "    number_of_pics = int(number_of_pics)\n",
        "    #batch_size= int(batch_size)\n",
        "\n",
        "    output = [Pipeline(prompt = input_prompt, num_inference_steps= 20).images for i in range(number_of_pics)]\n",
        "    for index, image in enumerate(output):\n",
        "        file_name = f\"image{index}.jpg\"\n",
        "        image[0].save(os.path.join(output_folder,file_name))\n",
        "    return output"
      ],
      "metadata": {
        "id": "Azk1OUrTnmFN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Loading_Lora(lora_name_string):\n",
        "    os.listdir(lora_folder)\n",
        "    if lora_name_string in lora_folder:\n",
        "        Pipeline.load_lora_weights(os.path.join(lora_folder, lora_name_string))\n",
        "        return Pipeline"
      ],
      "metadata": {
        "id": "Fog9h144NlGs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_images(images:list):\n",
        "    image_paths = [os.path.join(output_folder, f\"image{i}.jpg\" ) for i in range(len(images))]\n",
        "    num_images = len(images)\n",
        "    num_rows = int(num_images ** 0.5)\n",
        "    num_cols = (num_images + num_rows - 1) // num_rows\n",
        "    fig, axes = plt.subplots(num_rows, num_cols)\n",
        "    for i, ax in enumerate(axes.ravel()):\n",
        "        if i < len(image_paths):\n",
        "            img = Image.open(image_paths[i])\n",
        "            ax.imshow(img)\n",
        "            ax.axis('off')\n",
        "\n",
        "    i = len(os.listdir(plot_folder))\n",
        "    while True:\n",
        "        plt_name = os.path.join(plot_folder, f\"plot{i}.jpg\")\n",
        "        if plt_name in os.listdir(plot_folder):\n",
        "            plt_name = os.path.join(plot_folder, f\"plot{i+1}.jpg\")\n",
        "            i += 1\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    plt.savefig(plt_name, bbox_inches=\"tight\")\n",
        "    plt.close()\n",
        "    for image_path in image_paths:\n",
        "       os.remove(image_path)\n"
      ],
      "metadata": {
        "id": "jm0bSKMy8kNf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Lora_Comparision()"
      ],
      "metadata": {
        "id": "Zqwp4uDTT6ak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the *Code Cell below* to run the pipeline using the **functions** defined in the *above code cell*\n",
        "For example-\n",
        "\n",
        "1.  **`basic_generator(\"anime waifu\", 2)`** will get you 2 individual anime waifus pics in the output folder\n",
        "2.  **`plot_images(basic_generator(\"anime waifus\",12))`** will you get you your 12 anime waifus on a single image in the plot directory\n",
        "\n"
      ],
      "metadata": {
        "id": "YkO6LaUX7r03"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_images(basic_generator(\"batman by the beach\",2))"
      ],
      "metadata": {
        "id": "q7sdjXSIdE6_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "run the **`Gradio`** interface (not completed)"
      ],
      "metadata": {
        "id": "Jetj740XVb2-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Iface = gr.Interface(fn=user_inputs, inputs= [\"text\",\"number\"], outputs= \"image\")\n",
        "#Iface.launch(debug=True)"
      ],
      "metadata": {
        "id": "dg4vYAZnVaK1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}