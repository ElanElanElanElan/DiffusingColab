{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "qJZ-zuXV0JmT",
        "5BC7kJb6hqiK"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ElanElanElanElan/DiffusingColab/blob/main/DiffusingColab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Diffusing colab by using python! the way god intended**\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "qJZ-zuXV0JmT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gDkEJvt4e1-Y",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title **Installing** and **importing** all necessary and semi necessary stuff\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "import os\n",
        "import shutil\n",
        "import time\n",
        "from PIL import Image\n",
        "import torch\n",
        "from IPython.utils import io\n",
        "import re\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "with io.capture_output() as captured:\n",
        "    !pip install --upgrade gradio diffusers accelerate transformers xformers safetensors\n",
        "    !apt-get install aria2\n",
        "    output_text = captured.stdout\n",
        "    errors = re.findall(r'(?i).error.', output_text)\n",
        "    for error in errors:\n",
        "        print(error)\n",
        "import gradio as gr\n",
        "from diffusers import DiffusionPipeline, StableDiffusionPipeline, StableDiffusionXLPipeline, AutoencoderTiny, EulerDiscreteScheduler, DDPMScheduler, KDPM2DiscreteScheduler, DPMSolverMultistepScheduler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title  create the setup folders (Necessary) and use Google Drive (optional)\n",
        "\n",
        "USE_GDRIVE = False #@param {type: \"boolean\"}\n",
        "if USE_GDRIVE:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "!mkdir Loras\n",
        "!mkdir Outputs\n",
        "!mkdir Plots\n",
        "lora_folder = '/content/Loras'\n",
        "output_folder = '/content/Outputs'\n",
        "plot_folder = \"/content/Plots\""
      ],
      "metadata": {
        "id": "zaXRyA4xwbHA",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download Loras from Civitai (provide a link with api otherwise it will be a faulty download)(Dont interlink between 1.5 and sdxl loras)\n",
        "link = \"https://civitai.com/api/download/models/145829/\" #@param {type: \"string\"}\n",
        "name = \"cutecomicstylexl.safetensors\" #@param {type: \"string\"}\n",
        "\n",
        "if not name.endswith('.safetensors'):\n",
        "    raise ValueError(\"doesnt have .safetensors in the name\")\n",
        "\n",
        "!aria2c -x 16 {link} -d {lora_folder} -o {name}\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "JAbtvCAD-LAz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title select which model and optimization to use (Necessary)\n",
        "Enter_model = \"BaseSdxl\"  # @param [\"BaseSdxl\", \"base-1.5\", \"openjourney(realistic1.5)\"]\n",
        "Enter_optimisation = \"optimised\"  # @param [\"none\", 'optimised']\n",
        "\n",
        "match Enter_model:\n",
        "    case 'BaseSdxl':\n",
        "        model_id = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
        "        Pipeline = StableDiffusionXLPipeline.from_pretrained(model_id, torch_dtype=torch.float16, variant=\"fp16\", safety_checker=None, use_safetensors=True)\n",
        "    case 'base-1.5':\n",
        "        model_id = \"runwayml/stable-diffusion-v1-5\"\n",
        "        Pipeline = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16, variant=\"fp16\", safety_checker=None, use_safetensors=True)\n",
        "    case 'openjourney(realistic1.5)':\n",
        "        model_id = \"upro/openjourney\"\n",
        "        Pipeline = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16, variant=\"fp16\", safety_checker=None, use_safetensors=True)\n",
        "\n",
        "match Enter_optimisation:\n",
        "    case 'optimised':\n",
        "        if Enter_model == \"BaseSdxl\":\n",
        "            Pipeline.vae = AutoencoderTiny.from_pretrained(\"madebyollin/taesdxl\", torch_dtype=torch.float16)\n",
        "            Pipeline.enable_attention_slicing()\n",
        "            Pipeline.enable_vae_slicing()\n",
        "            Pipeline.enable_vae_tiling()\n",
        "        else:\n",
        "            Pipeline.vae = AutoencoderTiny.from_pretrained(\"madebyollin/taesd\", torch_dtype=torch.float16)\n",
        "            Pipeline.enable_attention_slicing()\n",
        "            Pipeline.enable_vae_slicing()\n",
        "            Pipeline.enable_vae_tiling()\n",
        "    case \"none\":\n",
        "        Pipeline.disable_attention_slicing()\n",
        "        Pipeline.disable_vae_tiling()\n",
        "        Pipeline.disable_vae_slicing()\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "bPu4OrqN8FRK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Generate (-1 seed value = random generate)\n",
        "def seed_selector(seed):\n",
        "    with torch.no_grad():\n",
        "        if seed != -1:\n",
        "            return torch.Generator(device = \"cuda\").manual_seed(seed)\n",
        "        random_seed = torch.Generator().seed()\n",
        "        print(f\"seed for the image is {random_seed}\")\n",
        "        return torch.Generator(device = \"cuda\").manual_seed(random_seed)\n",
        "\n",
        "def Loading_Lora(lora_name_string):\n",
        "    lora_list = os.listdir(lora_folder)\n",
        "    matching_files = [filename for filename in lora_list if lora_name_string in filename and filename.endswith(\".safetensors\")]\n",
        "\n",
        "    if not matching_files:\n",
        "        print(f\"No matching files found for '{lora_name_string}' in {lora_folder}.\")\n",
        "        return None\n",
        "\n",
        "    if len(matching_files) == 1:\n",
        "\n",
        "        selected_file = matching_files[0]\n",
        "        Pipeline.load_lora_weights(os.path.join(lora_folder, selected_file))\n",
        "        return Pipeline\n",
        "    else:\n",
        "        print(\"more than one lora with matching names, be more specific in the naming\")\n",
        "\n",
        "def basic_generator(input_prompt: str, neg_prompt:str, number_of_pics: int, steps: int, width = 1024, height = 1024, seed: int = -1, Use_Lora: bool = False, Lora_name: str = \"\", Lora_comparision: bool = False, scheduler=\"DPMSolverMultistep\") -> list:\n",
        "    number_of_pics = int(number_of_pics)\n",
        "    steps = int(steps)\n",
        "    width = int(width)\n",
        "    height = int(height)\n",
        "    seed = int(seed)\n",
        "    output = []\n",
        "    generator = None\n",
        "    if len(Lora_name) == 0:\n",
        "        Lora_name = None\n",
        "    match scheduler:\n",
        "        case \"EulerDiscrete\":\n",
        "            Pipeline.scheduler = EulerDiscreteScheduler.from_config(Pipeline.scheduler.config)\n",
        "        case \"DDPM\":\n",
        "            Pipeline.scheduler = DDPMScheduler.from_config(Pipeline.scheduler.config)\n",
        "        case \"KDPM2Discrete\":\n",
        "            Pipeline.scheduler = KDPM2DiscreteScheduler.from_config(Pipeline.scheduler.config)\n",
        "        case \"DPMSolverMultistep\":\n",
        "            Pipeline.scheduler = DPMSolverMultistepScheduler.from_config(Pipeline.scheduler.config)\n",
        "        case _:\n",
        "            print(f\"Unknown scheduler: {scheduler}\")\n",
        "    Pipeline.to('cuda')\n",
        "\n",
        "    if Use_Lora and Lora_name is None:\n",
        "        raise ValueError(\"If 'Use_Lora' is True, 'Lora_name' must be provided.\")\n",
        "    elif not Use_Lora and Lora_name is not None:\n",
        "        raise ValueError(\"If 'Use_Lora' is False, 'Lora_name' should not be provided.\")\n",
        "\n",
        "\n",
        "    if Use_Lora:\n",
        "        Loading_Lora(Lora_name)\n",
        "        for i in range(number_of_pics):\n",
        "            output.append(Pipeline(prompt = input_prompt, num_inference_steps= steps, generator = seed_selector(seed), width = width, height = height).images)\n",
        "        Pipeline.unload_lora_weights()\n",
        "\n",
        "    elif Lora_comparision:\n",
        "        for lora in os.listdir(lora_folder):\n",
        "            if lora.endswith(\".safetensors\"):\n",
        "                Loading_Lora(lora)\n",
        "                output.append(Pipeline(prompt = input_prompt, num_inference_steps= steps, generator = seed_selector(seed), width = width, height = height).images)\n",
        "                Pipeline.unload_lora_weights()\n",
        "\n",
        "    else:\n",
        "        for i in range(number_of_pics):\n",
        "            output.append(Pipeline(prompt = input_prompt, num_inference_steps= steps, generator = seed_selector(seed), width = width, height = height).images)\n",
        "\n",
        "\n",
        "    image_paths = []\n",
        "    for index, image in enumerate(output):\n",
        "        while True:\n",
        "            file_name = f\"image{index}.png\"\n",
        "            if file_name not in os.listdir(output_folder):\n",
        "                break\n",
        "            index += 1\n",
        "        image[0].save(os.path.join(output_folder, file_name), \"PNG\")\n",
        "        image_paths.append(os.path.join(output_folder, file_name))\n",
        "    return image_paths\n",
        "\n",
        "def plot_images(image_paths:list = None):\n",
        "    if image_paths is None:\n",
        "        image_paths = [\n",
        "            os.path.join(output_folder, filename)\n",
        "            for filename in os.listdir(output_folder)\n",
        "            if os.path.isfile(os.path.join(output_folder, filename))\n",
        "        ]\n",
        "    num_images = len(image_paths)\n",
        "    num_rows = int(num_images ** 0.5)\n",
        "    num_cols = (num_images + num_rows - 1) // num_rows\n",
        "    total_width = max(img.width for img in map(Image.open, image_paths)) * num_cols\n",
        "    total_height = max(img.height for img in map(Image.open, image_paths)) * num_rows\n",
        "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(total_width/100 , total_height/100))\n",
        "    for i, ax in enumerate(axes.ravel()):\n",
        "        if i < len(image_paths):\n",
        "            img = Image.open(image_paths[i])\n",
        "            ax.imshow(img)\n",
        "            ax.axis('off')\n",
        "            filename = os.path.basename(image_paths[i])\n",
        "            ax.set_title(filename, fontsize=20)\n",
        "    plt.subplots_adjust(wspace=0.01, hspace=0.01)\n",
        "    i = len(os.listdir(plot_folder))\n",
        "    while True:\n",
        "        plt_name = os.path.join(plot_folder, f\"plot{i}.jpg\")\n",
        "        if plt_name in os.listdir(plot_folder):\n",
        "            plt_name = os.path.join(plot_folder, f\"plot{i+1}.jpg\")\n",
        "            i += 1\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    plt.savefig(plt_name, bbox_inches=\"tight\")\n",
        "\n",
        "def showcase(Image_paths : list):\n",
        "    for filename in Image_paths:\n",
        "        img = cv2.imread(filename)\n",
        "        cv2_imshow(img)\n",
        "prompt = \"comic style  image of a woman riding a bike\" # @param {type:\"string\"}\n",
        "neg_prompt = \"dull, realistic, broken, incomplete, out of shape\" # @param {type:\"string\"}\n",
        "height = 1024 # @param {type:\"integer\"}\n",
        "width = 1024 # @param {type:\"integer\"}\n",
        "images = 1 # @param {type:\"integer\"}\n",
        "steps = 25 # @param {type:\"integer\"}\n",
        "seed = -1 #@param {type: \"integer\"}\n",
        "clean_before_gen = True # @param {type:\"boolean\"}\n",
        "scheduler = \"EulerDiscrete\" # @param [\"EulerDiscrete\",\"DDPM\",\"KDPM2Discrete\",\"DPMSolverMultistep\"]\n",
        "plot_generated_images = False #@param {type:'boolean'}\n",
        "Use_Lora = True #@param {type:'boolean'}\n",
        "Lora_name = 'cutecomicstylexl' # @param {type:\"string\"}\n",
        "Lora_comparision = False #@param {type: \"boolean\"}\n",
        "# @markdown comapares all loras in the lora folder and plots them (disregards number of pics)\n",
        "if clean_before_gen:\n",
        "  !find {output_folder} -type f -delete\n",
        "  !find {plot_folder} -type f -delete\n",
        "if plot_generated_images:\n",
        "    if images == 1 and Lora_comparision == False:\n",
        "       raise ValueError(\"cant plot a single image\")\n",
        "    else:\n",
        "        plot_images(basic_generator(prompt,neg_prompt,images,steps,height = height,width= width, scheduler = scheduler, seed = seed, Use_Lora = Use_Lora, Lora_name = Lora_name, Lora_comparision = Lora_comparision))\n",
        "else:\n",
        "    showcase(basic_generator(prompt,neg_prompt,images,steps,height = height,width= width, scheduler = scheduler, seed = seed, Use_Lora = Use_Lora, Lora_name = Lora_name, Lora_comparision = Lora_comparision))"
      ],
      "metadata": {
        "id": "4sLH-Q9Xz-yB",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Utility cells below**\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "5BC7kJb6hqiK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title run the cell to copy stuff from gdrive like loras, to the appropriate folders\n",
        "user_input = \"Marcelinexl\" #@param {type:\"string\"}\n",
        "google_drive_folder = \"/content/drive/\" #@param {type:\"string\"}\n",
        "directoryto = lora_folder # @param [\"lora_folder\"] {type:\"raw\"}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "full_content = os.listdir(google_drive_folder)\n",
        "\n",
        "\n",
        "for file in full_content:\n",
        "    if user_input in file:\n",
        "        source_path = os.path.join(google_drive_folder, file)\n",
        "        shutil.copy(source_path, directoryto)\n"
      ],
      "metadata": {
        "id": "M0GCgjFP1Kh3",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title run the cell to plot all images in images\n",
        "plot_images()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "e9Fe9f5KK3IF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title run the **`Gradio`** interface (not completed)\n",
        "#Iface = gr.Interface(fn=user_inputs, inputs= [\"text\",\"number\"], outputs= \"image\")\n",
        "#Iface.launch(debug=True)"
      ],
      "metadata": {
        "id": "dg4vYAZnVaK1",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}