{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "qJZ-zuXV0JmT",
        "5BC7kJb6hqiK"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ElanElanElanElan/DiffusingColab/blob/InTesting/DiffusingColab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Diffusing colab by using python! the way god intended**\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "qJZ-zuXV0JmT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gDkEJvt4e1-Y",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title **Installing** and **importing** all necessary and semi necessary stuff\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "import os\n",
        "import shutil\n",
        "import time\n",
        "from PIL import Image\n",
        "import torch\n",
        "from IPython.utils import io\n",
        "import re\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "with io.capture_output() as captured:\n",
        "    !pip install --upgrade gradio diffusers accelerate transformers xformers safetensors\n",
        "    output_text = captured.stdout\n",
        "    errors = re.findall(r'(?i).error.', output_text)\n",
        "    for error in errors:\n",
        "        print(error)\n",
        "import gradio as gr\n",
        "from diffusers import DiffusionPipeline, StableDiffusionPipeline, StableDiffusionXLPipeline, AutoencoderTiny, EulerDiscreteScheduler, DDPMScheduler, KDPM2DiscreteScheduler, DPMSolverMultistepScheduler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title  create the setup folders (Necessary) and use Google Drive (optional)\n",
        "\n",
        "USE_GDRIVE = False #@param {type: \"boolean\"}\n",
        "if USE_GDRIVE:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "!mkdir Loras\n",
        "!mkdir Outputs\n",
        "!mkdir Plots\n",
        "lora_folder = '/content/Loras'\n",
        "output_folder = '/content/Outputs'\n",
        "plot_folder = \"/content/Plots\""
      ],
      "metadata": {
        "id": "zaXRyA4xwbHA",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title select which model and optimization to use (Necessary)\n",
        "Enter_model = \"BaseSdxl\" # @param [\"BaseSdxl\", \"base-1.5\", \"openjourney(realistic1.5)\" ]\n",
        "if Enter_model == 'BaseSdxl':\n",
        "    model_id = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
        "    Pipeline =  StableDiffusionXLPipeline.from_pretrained(model_id, torch_dtype=torch.float16,variant=\"fp16\", safety_checker=None, use_safetensors=True)\n",
        "    Pipeline.scheduler = DPMSolverMultistepScheduler.from_config(Pipeline.scheduler.config)\n",
        "elif Enter_model == \"base-1.5\":\n",
        "    model_id = \"runwayml/stable-diffusion-v1-5\"\n",
        "    Pipeline =  StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16,variant=\"fp16\", safety_checker=None, use_safetensors=True)\n",
        "    Pipeline.scheduler = DPMSolverMultistepScheduler.from_config(Pipeline.scheduler.config)\n",
        "elif Enter_model == \"openjourney(realistic1.5)\":\n",
        "    model_id = \"upro/openjourney\"\n",
        "    Pipeline =  StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16,variant=\"fp16\", safety_checker=None, use_safetensors=True)\n",
        "    Pipeline.scheduler = DPMSolverMultistepScheduler.from_config(Pipeline.scheduler.config)\n",
        "enter_optimisation = \"optimised\" #@param [\"none\",'optimised']\n",
        "if enter_optimisation == \"optimised\" and Enter_model == 'BaseSdxl':\n",
        "    Pipeline.vae = AutoencoderTiny.from_pretrained(\"madebyollin/taesdxl\", torch_dtype=torch.float16)\n",
        "    Pipeline.enable_attention_slicing()\n",
        "    Pipeline.enable_vae_slicing()\n",
        "    Pipeline.enable_vae_tiling()\n",
        "elif enter_optimisation == \"optimised\":\n",
        "    Pipeline.vae = AutoencoderTiny.from_pretrained(\"madebyollin/taesd\", torch_dtype=torch.float16)\n",
        "    Pipeline.enable_attention_slicing()\n",
        "    Pipeline.enable_vae_slicing()\n",
        "    Pipeline.enable_vae_tiling()\n",
        "else:\n",
        "    Pipeline.disable_attention_slicing()\n",
        "    Pipeline.disable_vae_tiling()\n",
        "    Pipeline.disable_vae_slicing()"
      ],
      "metadata": {
        "id": "a0kKOEJ_Xn0z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Generate (-1 seed value = random generate)\n",
        "def Loading_Lora(lora_name_string):\n",
        "    lora_list = os.listdir(lora_folder)\n",
        "    matching_files = [filename for filename in lora_list if lora_name_string in filename]\n",
        "\n",
        "    if not matching_files:\n",
        "        print(f\"No matching files found for '{lora_name_string}' in {lora_folder}.\")\n",
        "        return None\n",
        "\n",
        "    if len(matching_files) == 1:\n",
        "\n",
        "        selected_file = matching_files[0]\n",
        "        Pipeline.load_lora_weights(os.path.join(lora_folder, selected_file))\n",
        "        return Pipeline\n",
        "    else:\n",
        "        print(\"more than one lora with matching names, be more specific in the naming\")\n",
        "\n",
        "def basic_generator(input_prompt: str, neg_prompt:str, number_of_pics: int, steps: int, width = 1024, height = 1024, seed: int = -1, Use_Lora: bool = False, Lora_name: str = \"\", Lora_comparision: bool = False, scheduler=\"DPMSolverMultistep\") -> list:\n",
        "    number_of_pics = int(number_of_pics)\n",
        "    steps = int(steps)\n",
        "    width = int(width)\n",
        "    height = int(height)\n",
        "    seed = int(seed)\n",
        "    output = []\n",
        "    generator = None\n",
        "    if len(Lora_name) == 0:\n",
        "        Lora_name = None\n",
        "    match scheduler:\n",
        "        case \"EulerDiscrete\":\n",
        "            Pipeline.scheduler = EulerDiscreteScheduler.from_config(Pipeline.scheduler.config)\n",
        "        case \"DDPM\":\n",
        "            Pipeline.scheduler = DDPMScheduler.from_config(Pipeline.scheduler.config)\n",
        "        case \"KDPM2Discrete\":\n",
        "            Pipeline.scheduler = KDPM2DiscreteScheduler.from_config(Pipeline.scheduler.config)\n",
        "        case \"DPMSolverMultistep\":\n",
        "            Pipeline.scheduler = DPMSolverMultistepScheduler.from_config(Pipeline.scheduler.config)\n",
        "        case _:\n",
        "            print(f\"Unknown scheduler: {scheduler}\")\n",
        "    Pipeline.to('cuda')\n",
        "    if Use_Lora and Lora_name is None:\n",
        "        raise ValueError(\"If 'Use_Lora' is True, 'Lora_name' must be provided.\")\n",
        "    elif not Use_Lora and Lora_name is not None:\n",
        "        raise ValueError(\"If 'Use_Lora' is False, 'Lora_name' should not be provided.\")\n",
        "    if Use_Lora:\n",
        "        Loading_Lora(Lora_name)\n",
        "        for i in range(number_of_pics):\n",
        "            with torch.no_grad():\n",
        "                if seed != -1:\n",
        "                    generator = torch.Generator(device = \"cuda\").manual_seed(seed)\n",
        "                else:\n",
        "                    random_seed = torch.Generator().seed()\n",
        "                    generator = torch.Generator(device = \"cuda\").manual_seed(random_seed)\n",
        "                    print(f\"seed for the image is {random_seed}\")\n",
        "            output.append(Pipeline(prompt = input_prompt, num_inference_steps= steps, generator = generator, width = width, height = height).images)\n",
        "        Pipeline.unload_lora_weights()\n",
        "    elif Lora_comparision:\n",
        "        output = []\n",
        "        for lora in os.listdir(lora_folder):\n",
        "            Loading_Lora(lora)\n",
        "            with torch.no_grad():\n",
        "                if seed != -1:\n",
        "                    generator = torch.Generator(device = \"cuda\").manual_seed(seed)\n",
        "                else:\n",
        "                    random_seed = torch.Generator().seed()\n",
        "                    generator = torch.Generator(device = \"cuda\").manual_seed(random_seed)\n",
        "                    print(f\"seed for the image is {random_seed}\")\n",
        "            output.append(Pipeline(prompt = input_prompt, num_inference_steps= steps, generator = generator, width = width, height = height).images)\n",
        "            Pipeline.unload_lora_weights()\n",
        "    else:\n",
        "        for i in range(number_of_pics):\n",
        "            with torch.no_grad():\n",
        "                 if seed != -1:\n",
        "                    generator = torch.Generator(device = \"cuda\").manual_seed(seed)\n",
        "                 else:\n",
        "                     random_seed = torch.Generator().seed()\n",
        "                     generator = torch.Generator(device = \"cuda\").manual_seed(random_seed)\n",
        "                     print(f\"seed for the image is {random_seed}\")\n",
        "            output.append(Pipeline(prompt = input_prompt, num_inference_steps= steps, generator = generator, width = width, height = height).images)\n",
        "    image_paths = []\n",
        "    for index, image in enumerate(output):\n",
        "        file_name = f\"image{index}.png\"\n",
        "        if file_name in os.listdir(output_folder):\n",
        "            file_name = f\"image{len(os.listdir(output_folder))}.png\"\n",
        "        image[0].save(os.path.join(output_folder, file_name), \"PNG\")\n",
        "        image_paths.append(os.path.join(output_folder,file_name))\n",
        "\n",
        "    return image_paths\n",
        "\n",
        "def plot_images(image_paths:list = None):\n",
        "    if image_paths is None:\n",
        "        image_paths = [\n",
        "            os.path.join(output_folder, filename)\n",
        "            for filename in os.listdir(output_folder)\n",
        "            if os.path.isfile(os.path.join(output_folder, filename))\n",
        "        ]\n",
        "    num_images = len(image_paths)\n",
        "    num_rows = int(num_images ** 0.5)\n",
        "    num_cols = (num_images + num_rows - 1) // num_rows\n",
        "    total_width = max(img.width for img in map(Image.open, image_paths)) * num_cols\n",
        "    total_height = max(img.height for img in map(Image.open, image_paths)) * num_rows\n",
        "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(total_width/100 , total_height/100))\n",
        "    for i, ax in enumerate(axes.ravel()):\n",
        "        if i < len(image_paths):\n",
        "            img = Image.open(image_paths[i])\n",
        "            ax.imshow(img)\n",
        "            ax.axis('off')\n",
        "    plt.subplots_adjust(wspace=0.01, hspace=0.01)\n",
        "    i = len(os.listdir(plot_folder))\n",
        "    while True:\n",
        "        plt_name = os.path.join(plot_folder, f\"plot{i}.jpg\")\n",
        "        if plt_name in os.listdir(plot_folder):\n",
        "            plt_name = os.path.join(plot_folder, f\"plot{i+1}.jpg\")\n",
        "            i += 1\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    plt.savefig(plt_name, bbox_inches=\"tight\")\n",
        "\n",
        "def showcase(Image_paths : list):\n",
        "    for filename in Image_paths:\n",
        "        img = cv2.imread(filename)\n",
        "        cv2_imshow(img)\n",
        "prompt = \"close up image of Batman\" # @param {type:\"string\"}\n",
        "neg_prompt = \"far away, full body shot\" # @param {type:\"string\"}\n",
        "height = 1024 # @param {type:\"integer\"}\n",
        "width = 1024 # @param {type:\"integer\"}\n",
        "images = 1 # @param {type:\"integer\"}\n",
        "steps = 25 # @param {type:\"integer\"}\n",
        "seed = -1 #@param {type: \"integer\"}\n",
        "clean_before_gen = False # @param {type:\"boolean\"}\n",
        "scheduler = \"EulerDiscrete\" # @param [\"EulerDiscrete\",\"DDPM\",\"KDPM2Discrete\",\"DPMSolverMultistep\"]\n",
        "plot_generated_images = False #@param {type:'boolean'}\n",
        "Use_Lora = False #@param {type:'boolean'}\n",
        "Lora_name = '' # @param {type:\"string\"}\n",
        "Lora_comparision = False #@param {type: \"boolean\"}\n",
        "# @markdown comapares all loras in the lora folder and plots them (disregards number of pics)\n",
        "if clean_before_gen:\n",
        "  !find {output_folder} -type f -delete\n",
        "  !find {plot_folder} -type f -delete\n",
        "if plot_generated_images:\n",
        "    if images == 1:\n",
        "       raise ValueError(\"cant plot a single image\")\n",
        "    else:\n",
        "        plot_images(basic_generator(prompt,neg_prompt,images,steps,height = height,width= width, scheduler = scheduler, seed = seed, Use_Lora = Use_Lora, Lora_name = Lora_name, Lora_comparision = Lora_comparision))\n",
        "else:\n",
        "    showcase(basic_generator(prompt,neg_prompt,images,steps,height = height,width= width, scheduler = scheduler, seed = seed, Use_Lora = Use_Lora, Lora_name = Lora_name, Lora_comparision = Lora_comparision))"
      ],
      "metadata": {
        "id": "4sLH-Q9Xz-yB",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Utility cells below**\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "5BC7kJb6hqiK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title run the cell to copy stuff from gdrive like loras, to the appropriate folders\n",
        "user_input = \".safetensors\" #@param {type:\"string\"}\n",
        "google_drive_folder = \"/content/drive/\" #@param {type:\"string\"}\n",
        "directoryto = lora_folder # @param [\"lora_folder\"] {type:\"raw\"}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "full_content = os.listdir(google_drive_folder)\n",
        "\n",
        "\n",
        "for file in full_content:\n",
        "    if user_input in file:\n",
        "        source_path = os.path.join(google_drive_folder, file)\n",
        "        shutil.copy(source_path, directoryto)\n"
      ],
      "metadata": {
        "id": "M0GCgjFP1Kh3",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title run the cell to plot all images in images\n",
        "plot_images()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "e9Fe9f5KK3IF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title run the **`Gradio`** interface (not completed)\n",
        "#Iface = gr.Interface(fn=user_inputs, inputs= [\"text\",\"number\"], outputs= \"image\")\n",
        "#Iface.launch(debug=True)"
      ],
      "metadata": {
        "id": "dg4vYAZnVaK1",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}