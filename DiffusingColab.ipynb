{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "qJZ-zuXV0JmT",
        "5BC7kJb6hqiK"
      ],
      "authorship_tag": "ABX9TyO3KJ40ybANbcjfJvvn2AJW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ElanElanElanElan/DiffusingColab/blob/InTesting/DiffusingColab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Diffusing colab by using python! the way god intended**\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "qJZ-zuXV0JmT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gDkEJvt4e1-Y",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title **Installing** and **importing** all neccesary and semi neccesary stuff\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "import os\n",
        "import shutil\n",
        "import time\n",
        "from PIL import Image\n",
        "import torch\n",
        "from IPython.utils import io\n",
        "import re\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "with io.capture_output() as captured:\n",
        "    !pip install --upgrade gradio diffusers accelerate transformers xformers safetensors\n",
        "    output_text = captured.stdout\n",
        "    errors = re.findall(r'(?i).error.', output_text)\n",
        "    for error in errors:\n",
        "        print(error)\n",
        "import gradio as gr\n",
        "from diffusers import DiffusionPipeline, StableDiffusionPipeline, StableDiffusionXLPipeline, AutoencoderTiny, EulerDiscreteScheduler, DDPMScheduler, KDPM2DiscreteScheduler, DPMSolverMultistepScheduler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title use drive(optional) and create the setup folders\n",
        "\n",
        "USE_GDRIVE = False #@param {type: \"boolean\"}\n",
        "if USE_GDRIVE:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "!mkdir Loras\n",
        "!mkdir Outputs\n",
        "!mkdir Plots\n",
        "lora_folder = '/content/Loras'\n",
        "output_folder = '/content/Outputs'\n",
        "plot_folder = \"/content/Plots\""
      ],
      "metadata": {
        "id": "zaXRyA4xwbHA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title select which model and optimization to use\n",
        "Enter_model = \"BaseSdxl\" # @param [\"BaseSdxl\", \"base-1.5\", \"openjourney(realistic1.5)\" ]\n",
        "if Enter_model == 'BaseSdxl':\n",
        "    model_id = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
        "    Pipeline =  StableDiffusionXLPipeline.from_pretrained(model_id, torch_dtype=torch.float16,variant=\"fp16\", safety_checker=None, use_safetensors=True)\n",
        "    Pipeline.scheduler = DPMSolverMultistepScheduler.from_config(Pipeline.scheduler.config)\n",
        "elif Enter_model == \"base-1.5\":\n",
        "    model_id = \"runwayml/stable-diffusion-v1-5\"\n",
        "    Pipeline =  StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16,variant=\"fp16\", safety_checker=None, use_safetensors=True)\n",
        "    Pipeline.scheduler = DPMSolverMultistepScheduler.from_config(Pipeline.scheduler.config)\n",
        "elif Enter_model == \"openjourney(realistic1.5)\":\n",
        "    model_id = \"upro/openjourney\"\n",
        "    Pipeline =  StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16,variant=\"fp16\", safety_checker=None, use_safetensors=True)\n",
        "    Pipeline.scheduler = DPMSolverMultistepScheduler.from_config(Pipeline.scheduler.config)\n",
        "enter_optimisation = \"optimised\" #@param [\"none\",'optimised']\n",
        "if enter_optimisation == \"optimised\" and Enter_model == 'BaseSdxl':\n",
        "    Pipeline.vae = AutoencoderTiny.from_pretrained(\"madebyollin/taesdxl\", torch_dtype=torch.float16)\n",
        "    Pipeline.enable_attention_slicing()\n",
        "    Pipeline.enable_vae_slicing()\n",
        "    Pipeline.enable_vae_tiling()\n",
        "elif enter_optimisation == \"optimised\":\n",
        "    Pipeline.vae = AutoencoderTiny.from_pretrained(\"madebyollin/taesd\", torch_dtype=torch.float16)\n",
        "    Pipeline.enable_attention_slicing()\n",
        "    Pipeline.enable_vae_slicing()\n",
        "    Pipeline.enable_vae_tiling()\n",
        "if enter_optimisation == \"none\":\n",
        "    Pipeline.disable_attention_slicing()\n",
        "    Pipeline.disable_vae_tiling()\n",
        "    Pipeline.disable_vae_slicing()"
      ],
      "metadata": {
        "id": "a0kKOEJ_Xn0z",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title run the cell below to define all the functions you will use (feel free to inspect)\n",
        "def Loading_Lora(lora_name_string):\n",
        "    lora_list = os.listdir(lora_folder)\n",
        "    matching_files = [filename for filename in lora_list if lora_name_string in filename]\n",
        "\n",
        "    if not matching_files:\n",
        "        print(f\"No matching files found for '{lora_name_string}' in {lora_folder}.\")\n",
        "        return None\n",
        "\n",
        "    if len(matching_files) == 1:\n",
        "\n",
        "        selected_file = matching_files[0]\n",
        "        Pipeline.load_lora_weights(os.path.join(lora_folder, selected_file))\n",
        "        return Pipeline\n",
        "    else:\n",
        "        print(\"more than one lora with matching names, be more specific in the naming\")\n",
        "\n",
        "def basic_generator(input_prompt: str, neg_prompt:str, number_of_pics: int, steps: int, width = 1024, height = 1024, Fixed_seed: bool = False, Use_Lora: bool = False, Lora_name: str = \"\", Lora_comparision: bool = False, scheduler=\"DPMSolverMultistep\") -> list:\n",
        "    number_of_pics = int(number_of_pics)\n",
        "    steps = int(steps)\n",
        "    width = int(width)\n",
        "    height = int(height)\n",
        "    output = []\n",
        "    if len(Lora_name) == 0:\n",
        "        Lora_name = None\n",
        "    generator= None\n",
        "    if scheduler==\"EulerDiscrete\":\n",
        "      Pipeline.scheduler = EulerDiscreteScheduler.from_config(Pipeline.scheduler.config)\n",
        "    elif scheduler==\"DDPM\":\n",
        "      Pipeline.scheduler = DDPMScheduler.from_config(Pipeline.scheduler.config)\n",
        "    elif scheduler==\"KDPM2Discrete\":\n",
        "      Pipeline.scheduler = KDPM2DiscreteScheduler.from_config(Pipeline.scheduler.config)\n",
        "    elif scheduler==\"DPMSolverMultistep\":\n",
        "      Pipeline.scheduler = DPMSolverMultistepScheduler.from_config(Pipeline.scheduler.config)\n",
        "    Pipeline.to('cuda')\n",
        "    if Use_Lora and Lora_name is None:\n",
        "        raise ValueError(\"If 'Use_Lora' is True, 'Lora_name' must be provided.\")\n",
        "    elif not Use_Lora and Lora_name is not None:\n",
        "        raise ValueError(\"If 'Use_Lora' is False, 'Lora_name' should not be provided.\")\n",
        "    if Use_Lora:\n",
        "        Loading_Lora(Lora_name)\n",
        "        for i in range(number_of_pics):\n",
        "            with torch.no_grad():\n",
        "                if Fixed_seed:\n",
        "                    generator = torch.Generator(device = \"cuda\").manual_seed(0)\n",
        "            output.append(Pipeline(prompt = input_prompt, num_inference_steps= steps, generator = generator, width = width, height = height).images)\n",
        "        Pipeline.unload_lora_weights()\n",
        "    elif Lora_comparision:\n",
        "        output = []\n",
        "        for lora in os.listdir(lora_folder):\n",
        "            Loading_Lora(lora)\n",
        "            with torch.no_grad():\n",
        "                if Fixed_seed:\n",
        "                    generator = torch.Generator(device = \"cuda\").manual_seed(0)\n",
        "            output.append(Pipeline(prompt = input_prompt, num_inference_steps= steps, generator = generator, width = width, height = height).images)\n",
        "            Pipeline.unload_lora_weights()\n",
        "    else:\n",
        "        for i in range(number_of_pics):\n",
        "            with torch.no_grad():\n",
        "                 if Fixed_seed:\n",
        "                    generator = torch.Generator(device = \"cuda\").manual_seed(0)\n",
        "            output.append(Pipeline(prompt = input_prompt, num_inference_steps= steps, generator = generator, width = width, height = height).images)\n",
        "    image_paths = []\n",
        "    for index, image in enumerate(output):\n",
        "        file_name = f\"image{index}.png\"\n",
        "        if file_name in os.listdir(output_folder):\n",
        "            file_name = f\"image{len(os.listdir(output_folder))}.png\"\n",
        "        image[0].save(os.path.join(output_folder, file_name), \"PNG\")\n",
        "        image_paths.append(os.path.join(output_folder,file_name))\n",
        "\n",
        "    return image_paths\n",
        "\n",
        "def plot_images(image_paths:list = None):\n",
        "    if image_paths is None:\n",
        "        image_paths = [\n",
        "            os.path.join(output_folder, filename)\n",
        "            for filename in os.listdir(output_folder)\n",
        "            if os.path.isfile(os.path.join(output_folder, filename))\n",
        "        ]\n",
        "    num_images = len(image_paths)\n",
        "    num_rows = int(num_images ** 0.5)\n",
        "    num_cols = (num_images + num_rows - 1) // num_rows\n",
        "    total_width = max(img.width for img in map(Image.open, image_paths)) * num_cols\n",
        "    total_height = max(img.height for img in map(Image.open, image_paths)) * num_rows\n",
        "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(total_width/100 , total_height/100))\n",
        "    for i, ax in enumerate(axes.ravel()):\n",
        "        if i < len(image_paths):\n",
        "            img = Image.open(image_paths[i])\n",
        "            ax.imshow(img)\n",
        "            ax.axis('off')\n",
        "    plt.subplots_adjust(wspace=0.01, hspace=0.01)\n",
        "    i = len(os.listdir(plot_folder))\n",
        "    while True:\n",
        "        plt_name = os.path.join(plot_folder, f\"plot{i}.jpg\")\n",
        "        if plt_name in os.listdir(plot_folder):\n",
        "            plt_name = os.path.join(plot_folder, f\"plot{i+1}.jpg\")\n",
        "            i += 1\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    plt.savefig(plt_name, bbox_inches=\"tight\")\n",
        "\n",
        "def showcase(Image_paths : list):\n",
        "    for filename in Image_paths:\n",
        "        img = cv2.imread(filename)\n",
        "        cv2_imshow(img)"
      ],
      "metadata": {
        "id": "Fog9h144NlGs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Generate\n",
        "\n",
        "prompt = \"a woman in a bikini on a beach, colorful, happy environment\" # @param {type:\"string\"}\n",
        "neg_prompt = \"blur, pixels, bad anatomy, bad hands, three hands, three legs, bad arms, missing legs, missing arms, poorly drawn face, bad face, fused face, cloned face, worst face, three crus, extra crus, fused crus, worst feet, three feet, fused feet, fused thigh, three thigh, fused thigh, extra thigh, worst thigh, missing fingers, extra fingers, ugly fingers, long fingers, horn, realistic photo, extra eyes, huge eyes, 2girl, amputation, disconnected limbs\" # @param {type:\"string\"}\n",
        "height = 1024 # @param {type:\"integer\"}\n",
        "width = 1024 # @param {type:\"integer\"}\n",
        "images = 1 # @param {type:\"integer\"}\n",
        "steps = 20 # @param {type:\"integer\"}\n",
        "Fixed_seed = True #@param {type: \"boolean\"}\n",
        "clean_before_gen = False # @param {type:\"boolean\"}\n",
        "scheduler = \"DPMSolverMultistep\" # @param [\"EulerDiscrete\",\"DDPM\",\"KDPM2Discrete\",\"DPMSolverMultistep\"]\n",
        "plot_generated_images = False #@param {type:'boolean'}\n",
        "Use_Lora = False #@param {type:'boolean'}\n",
        "Lora_name = '' # @param {type:\"string\"}\n",
        "Lora_comparision = False #@param {type: \"boolean\"}\n",
        "# @markdown comapares all loras in the lora folder and plots them (disregards number of pics)\n",
        "if clean_before_gen:\n",
        "  !find {output_folder} -type f -delete\n",
        "  !find {plot_folder} -type f -delete\n",
        "if plot_generated_images:\n",
        "    plot_images(basic_generator(prompt,neg_prompt,images,steps,height = height,width= width, scheduler = scheduler, Fixed_seed = Fixed_seed, Use_Lora = Use_Lora, Lora_name = Lora_name))\n",
        "else:\n",
        "    showcase(basic_generator(prompt,neg_prompt,images,steps,height = height,width= width, scheduler = scheduler, Fixed_seed = Fixed_seed, Use_Lora = Use_Lora, Lora_name = Lora_name))"
      ],
      "metadata": {
        "id": "4sLH-Q9Xz-yB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Utility cells below**\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "5BC7kJb6hqiK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title run the cell to copy stuff from gdrive like loras, to the appropriate folders\n",
        "user_input = \".safetensors\" #@param {type:\"string\"}\n",
        "google_drive_folder = \"/content/drive/MyDrive/Ai downloadables (sfw) /Ai art/Ai art Downloadables\" #@param {type:\"string\"}\n",
        "directoryto = lora_folder # @param [\"lora_folder\"] {type:\"raw\"}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "full_content = os.listdir(google_drive_folder)\n",
        "\n",
        "\n",
        "for file in full_content:\n",
        "    if user_input in file:\n",
        "        source_path = os.path.join(google_drive_folder, file)\n",
        "        shutil.copy(source_path, directoryto)\n"
      ],
      "metadata": {
        "id": "M0GCgjFP1Kh3",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title run the **`Gradio`** interface (not completed)\n",
        "#Iface = gr.Interface(fn=user_inputs, inputs= [\"text\",\"number\"], outputs= \"image\")\n",
        "#Iface.launch(debug=True)"
      ],
      "metadata": {
        "id": "dg4vYAZnVaK1",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}